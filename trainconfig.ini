[generate]
lock_ui = yes               # INI 강제 적용(yes면 UI 슬라이더/입력 무시)
temperature = 0.3           # 샘플링 온도(낮을수록 보수적)
top_p = 0.9                 # 누적 확률 컷(0~1, 1이면 비적용에 가까움)
max_new_tokens = 128        # 생성 최대 토큰 수
repetition_penalty = 1.1    # 반복 패널티(>1 권장)
top_k = 0                   # 0=비적용, >0=상위 k 토큰만 샘플링
no_repeat_ngram_size = 0    # 0=비적용(>0이면 n-그램 반복 금지)
num_beams = 1               # 1=빔서치 미사용(>1이면 빔서치)
do_sample = yes             # 샘플링 사용 여부
seed = auto                 # auto=비결정 실행(고정 시드 원하면 정수 입력)
stop =                      # 중지 토큰 시퀀스(없으면 공란)

[train]                      ; 공통 기본(모드와 무관, 아키텍처/런타임 공통값만 유지)
grad_clip = 1.0             # 기울기 클리핑 한계
min_lr = 0.00001            # 최소 학습률(코드에서 ≥1e-5로 클램프)
use_mixed_precision = yes   # AMP(혼합 정밀도) 사용
model_dim = 256             # 모델 차원
ff_dim = 1024               # FFN 차원
num_heads = 8               # 어텐션 헤드 수
num_encoder_layers = 6      # 인코더 레이어 수
num_decoder_layers = 6      # 디코더 레이어 수
num_workers = 6             # DataLoader 워커 수(CPU 테스트는 0 권장)
pin_memory = yes            # 핀 메모리 사용
spm_model_path = models/spm.model  # SentencePiece 모델 경로

[pretrain]                   ; 모드별 하이퍼파라미터(여기 값이 [train]을 덮어씀)
epochs = 20                 # 학습 에포크 수(모드 전용)
batch_size = 48             # 배치 크기(모드 전용)
learning_rate = 0.0002      # 학습률(모드 전용)
dropout_ratio = 0.1         # 드롭아웃 비율(모드 전용)
resume = no                 # 체크포인트 이어 학습 여부(no=새로 시작, 기본 False)

[finetune]                   ; 모드별 하이퍼파라미터(여기 값이 [train]을 덮어씀)
epochs = 20                 # 학습 에포크 수(모드 전용)
batch_size = 48             # 배치 크기(모드 전용)
learning_rate = 0.0002      # 학습률(모드 전용)
dropout_ratio = 0.1         # 드롭아웃 비율(모드 전용)
resume = no                 # 체크포인트 이어 학습 여부(no=새로 시작, 기본 False)
