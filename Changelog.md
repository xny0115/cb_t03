# Changelog

## [v0.2.2] - 2025-08-08

### 버그 수정 (Bug Fixes)

-   **UI 연동 기능 구현 및 오류 수정:**
    -   **문제점:** UI에서 모델 삭제, 설정 조회/저장 기능을 사용해도 아무런 동작을 하지 않거나 오류가 발생하는 심각한 문제가 있었습니다. `WebBackend`에서 `ChatbotService`의 `get_config`, `save_config`, `delete_model` 함수를 호출하지만, 실제로는 해당 함수들이 구현되어 있지 않았습니다.
    -   **수정 사항:** `src/service/service.py`의 `ChatbotService` 클래스에 누락되었던 위 3개 함수를 모두 구현하여 UI와 백엔드 기능이 정상적으로 연동되도록 수정했습니다.
    -   `delete_model`은 `AGENTS.md` 지침에 따라 `models` 폴더 내의 모든 `.pth` 파일을 삭제하도록 구현했습니다.

-   **모델 GPU 로딩 오류 수정:**
    -   **문제점:** `AGENTS.md`에서 GPU 사용을 강제하고 있음에도 불구하고, 모델을 불러올 때 하드코딩된 `map_location='cpu'` 설정 때문에 모델이 항상 CPU에서만 실행되었습니다. 이로 인해 훈련 및 추론 속도가 현저히 저하되어 사실상 사용이 불가능했습니다.
    -   **수정 사항:**
        1.  `ChatbotService`가 시작될 때 `cuda` 장치를 우선적으로 감지하여 `self.device`에 저장하도록 변경했습니다.
        2.  `src/model/transformer.py`의 `load_transformer` 함수가 `device`를 인자로 받아, `torch.load` 시 `map_location`으로 사용하도록 수정했습니다.
        3.  서비스 전반에 걸쳐 모델과 텐서가 일관되게 지정된 `device`(GPU) 상에서 동작하도록 보장하여, 프로젝트 요구사항을 충족하고 성능을 정상화했습니다.

## [v0.2.1] - 2025-08-09

### 세부 변경 내역
- SentencePiece 토크나이저 학습 스크립트에 다중 인코딩 처리와 학습 성공 여부 검증 로깅을 추가함.
- `SentencePieceTokenizer` 클래스를 도입하고 문자 단위 토크나이저 관련 코드를 완전히 제거함.
- 트랜스포머 `generate` 메소드에 Top-k, Top-p, Temperature 샘플링을 적용하고 모델 저장/로드 로직을 단순화함.
- 학습 및 서비스 모듈을 전면 교체하여 GPU 전용 학습 루프, 체크포인트 복구, 예외 처리 로직을 강화함.
- 설정 파일에 `tokenizer_path` 항목을 추가하고 백엔드 오류 처리 로직을 개선함.

## [v0.2.0] - 2025-08-08

### 주요 변경 사항 (Major Changes)

-   **핵심 아키텍처 리팩터링 (Core Architecture Refactoring):** 프로젝트의 전반적인 안정성, 성능, 확장성을 개선하기 위해 대대적인 아키텍처 리팩터링을 진행했습니다.

### 세부 변경 내역 (Details)

#### 1. 토크나이저 교체 (`CharTokenizer` -> `SentencePiece`)
-   **문제점:** 기존의 문자(Character) 단위 토크나이저는 한국어의 의미 구조를 학습하기 어려워 모델의 성능과 학습 속도를 저하 시키는 결정적인 원인이었습니다.
-   **개선 사항:**
    -   `SentencePiece` (BPE) 기반의 서브워드(Subword) 토크나이저를 도입하여, 모델이 단어의 의미 단위를 효과적으로 학습할 수 있도록 변경했습니다.
    -   이를 통해 모델의 대화 품질 향상과 학습 속도 개선을 기대할 수 있습니다.
    -   `requirements.txt`에 `sentencepiece` 라이브러리를 추가했습니다.

#### 2. 오프라인 데이터 파이프라인 구축
-   **문제점:** 기존에는 학습 시작 시 매번 실시간으로 데이터를 정제하고 토크나이저 어휘 사전을 구축하여 비효율적이었습니다.
-   **개선 사항:**
    -   `scripts/prepare_data.py` 스크립트를 새로 추가했습니다.
    -   이 스크립트를 통해 사전에 전체 학습 데이터를 기반으로 토크나이저를 미리 학습시키고, 모델 파일(`spm_bpe_8k.model`)로 저장합니다.
    -   학습 시에는 미리 생성된 토크나이저를 불러와 사용하도록 변경하여, 학습 시작 시간을 단축하고 일관성을 확보했습니다.

#### 3. 고급 답변 생성(Sampling) 기능 구현
-   **문제점:** UI에는 Top-k, Top-p, Temperature 등 다양한 답변 생성 옵션이 있었지만, 실제 모델의 `generate` 함수에는 해당 기능이 구현되어 있지 않았습니다.
-   **개선 사항:**
    -   `src/model/transformer.py`의 `generate` 함수를 다시 작성하여, UI의 설정값이 실제 답변 생성 과정에 반영되도록 구현했습니다.
    -   `src/service/service.py`의 `infer` 메소드를 수정하여, 설정된 값을 모델에 전달하도록 연결했습니다.

#### 4. 코드 리팩터링 및 정리
-   **모델 저장/로드:** `src/model/transformer.py`의 모델 저장/로드 함수에서 비효율적인 어휘 사전(vocab) 직접 저장을 제거하고, 모델 설정(config)을 통해 어휘 크기를 관리하도록 변경했습니다.
-   **학습 파이프라인:** `src/training/simple.py`의 코드를 리팩터링하여, 새로운 토크나이저와 오프라인 데이터 파이프라인에 맞춰 동작하도록 단순화하고 명확하게 개선했습니다.
