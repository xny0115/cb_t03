# Changelog

## [v0.2.0] - 2025-08-08

### 주요 변경 사항 (Major Changes)

-   **핵심 아키텍처 리팩터링 (Core Architecture Refactoring):** 프로젝트의 전반적인 안정성, 성능, 확장성을 개선하기 위해 대대적인 아키텍처 리팩터링을 진행했습니다.

### 세부 변경 내역 (Details)

#### 1. 토크나이저 교체 (`CharTokenizer` -> `SentencePiece`)
-   **문제점:** 기존의 문자(Character) 단위 토크나이저는 한국어의 의미 구조를 학습하기 어려워 모델의 성능과 학습 속도를 저하 시키는 결정적인 원인이었습니다.
-   **개선 사항:**
    -   `SentencePiece` (BPE) 기반의 서브워드(Subword) 토크나이저를 도입하여, 모델이 단어의 의미 단위를 효과적으로 학습할 수 있도록 변경했습니다.
    -   이를 통해 모델의 대화 품질 향상과 학습 속도 개선을 기대할 수 있습니다.
    -   `requirements.txt`에 `sentencepiece` 라이브러리를 추가했습니다.

#### 2. 오프라인 데이터 파이프라인 구축
-   **문제점:** 기존에는 학습 시작 시 매번 실시간으로 데이터를 정제하고 토크나이저 어휘 사전을 구축하여 비효율적이었습니다.
-   **개선 사항:**
    -   `scripts/prepare_data.py` 스크립트를 새로 추가했습니다.
    -   이 스크립트를 통해 사전에 전체 학습 데이터를 기반으로 토크나이저를 미리 학습시키고, 모델 파일(`spm_bpe_8k.model`)로 저장합니다.
    -   학습 시에는 미리 생성된 토크나이저를 불러와 사용하도록 변경하여, 학습 시작 시간을 단축하고 일관성을 확보했습니다.

#### 3. 고급 답변 생성(Sampling) 기능 구현
-   **문제점:** UI에는 Top-k, Top-p, Temperature 등 다양한 답변 생성 옵션이 있었지만, 실제 모델의 `generate` 함수에는 해당 기능이 구현되어 있지 않았습니다.
-   **개선 사항:**
    -   `src/model/transformer.py`의 `generate` 함수를 다시 작성하여, UI의 설정값이 실제 답변 생성 과정에 반영되도록 구현했습니다.
    -   `src/service/service.py`의 `infer` 메소드를 수정하여, 설정된 값을 모델에 전달하도록 연결했습니다.

#### 4. 코드 리팩터링 및 정리
-   **모델 저장/로드:** `src/model/transformer.py`의 모델 저장/로드 함수에서 비효율적인 어휘 사전(vocab) 직접 저장을 제거하고, 모델 설정(config)을 통해 어휘 크기를 관리하도록 변경했습니다.
-   **학습 파이프라인:** `src/training/simple.py`의 코드를 리팩터링하여, 새로운 토크나이저와 오프라인 데이터 파이프라인에 맞춰 동작하도록 단순화하고 명확하게 개선했습니다.
